{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9e3e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Individual Agent Performance: AgentDoubleDQN------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1002668.4375\n",
      "PnL: 2668.4375 \n",
      "\n",
      "Mean Return 1.1256307292443187e-06\n",
      "Volatility 4.916426460808678e-05 \n",
      "\n",
      "Sharpe Ratio: 0.022895302883451846\n",
      "Max Drawdown: -0.00012627206511627817\n",
      "Return over Max Drawdown: 21.13244522884938\n",
      "Win Rate 0.7678571428571429\n",
      "\n",
      "------Individual Agent Performance: AgentD3QN------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1000546.20703125\n",
      "PnL: 546.20703125 \n",
      "\n",
      "Mean Return 2.304080789795658e-07\n",
      "Volatility 2.781793648610572e-06 \n",
      "\n",
      "Sharpe Ratio: 0.08282716408337772\n",
      "Max Drawdown: -5.204385470403542e-05\n",
      "Return over Max Drawdown: 10.495130200623453\n",
      "Win Rate 0.7542262678803641\n",
      "\n",
      "------Individual Agent Performance: AgentDiscretePPO------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1005158.20703125\n",
      "PnL: 5158.20703125 \n",
      "\n",
      "Mean Return 2.1756792815597354e-06\n",
      "Volatility 9.82600604777447e-05 \n",
      "\n",
      "Sharpe Ratio: 0.022142051113967238\n",
      "Max Drawdown: -0.00031819159346166615\n",
      "Return over Max Drawdown: 16.211009772881134\n",
      "Win Rate 0.7724719101123596\n",
      "\n",
      "------Individual Agent Performance: AgentDiscreteA2C------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1005192.95703125\n",
      "PnL: 5192.95703125 \n",
      "\n",
      "Mean Return 2.1902658282966845e-06\n",
      "Volatility 9.825560032199777e-05 \n",
      "\n",
      "Sharpe Ratio: 0.02229151133491493\n",
      "Max Drawdown: -0.0003694481183721692\n",
      "Return over Max Drawdown: 14.055984515860475\n",
      "Win Rate 0.7599486521181001\n",
      "\n",
      "------Individual Agent Performance: AgentDiscreteSAC------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1000289.5625\n",
      "PnL: 289.5625 \n",
      "\n",
      "Mean Return 1.221667685424599e-07\n",
      "Volatility 3.5147636206166217e-06 \n",
      "\n",
      "Sharpe Ratio: 0.0347581748672553\n",
      "Max Drawdown: -0.00012172894231621311\n",
      "Return over Max Drawdown: 2.3787481801541315\n",
      "Win Rate 0.7780126849894292\n",
      "\n",
      "------Ensemble RL with Majority_Voting------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1005015.33203125\n",
      "PnL: 5015.33203125 \n",
      "\n",
      "Mean Return 2.1157036188023203e-06\n",
      "Volatility 9.830258547501728e-05 \n",
      "\n",
      "Sharpe Ratio: 0.02152235985024023\n",
      "Max Drawdown: -0.000432811600865835\n",
      "Return over Max Drawdown: 11.587794830872339\n",
      "Win Rate 0.756687898089172\n",
      "\n",
      "------Ensemble RL with Confidence_Based------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1000555.70703125\n",
      "PnL: 555.70703125 \n",
      "\n",
      "Mean Return 2.3441430959505172e-07\n",
      "Volatility 2.7811203616906037e-06 \n",
      "\n",
      "Sharpe Ratio: 0.08428772548792335\n",
      "Max Drawdown: -4.6921253627301744e-05\n",
      "Return over Max Drawdown: 11.843396932108888\n",
      "Win Rate 0.7532637075718016\n",
      "\n",
      "------Ensemble RL with Boltzmann_Addition------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1000554.20703125\n",
      "PnL: 554.20703125 \n",
      "\n",
      "Mean Return 2.3378174947480158e-07\n",
      "Volatility 2.7812557078192264e-06 \n",
      "\n",
      "Sharpe Ratio: 0.08405618685744976\n",
      "Max Drawdown: -4.692132397208159e-05\n",
      "Return over Max Drawdown: 11.811410768996385\n",
      "Win Rate 0.75390625\n",
      "\n",
      "------Ensemble RL with Boltzmann_Multiplication------\n",
      "\n",
      "Initial Asset: 1000000.0\n",
      "Final Asset: 1000555.70703125\n",
      "PnL: 555.70703125 \n",
      "\n",
      "Mean Return 2.3441430959505172e-07\n",
      "Volatility 2.7811203616906037e-06 \n",
      "\n",
      "Sharpe Ratio: 0.08428772548792335\n",
      "Max Drawdown: -4.6921253627301744e-05\n",
      "Return over Max Drawdown: 11.843396932108888\n",
      "Win Rate 0.7532637075718016\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from erl_config import Config, build_env\n",
    "from trade_simulator import EvalTradeSimulator\n",
    "from erl_agent import AgentD3QN, AgentDoubleDQN, AgentTwinD3QN\n",
    "from collections import Counter\n",
    "from metrics import sharpe_ratio, max_drawdown, return_over_max_drawdown\n",
    "\n",
    "from erl_agent import AgentPPO, AgentA2C, AgentDiscretePPO, AgentDiscreteA2C\n",
    "from erl_agent import AgentDiscreteSAC\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def to_python_number(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.cpu().item()\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "class EnsembleEvaluator:\n",
    "    def __init__(self, save_path, agent_classes, args: Config):\n",
    "        self.save_path = save_path\n",
    "        self.agent_classes = agent_classes\n",
    "\n",
    "        # args\n",
    "        self.args = args\n",
    "        self.agents = []\n",
    "        self.thresh = 0.001\n",
    "        self.num_envs = 1\n",
    "        self.state_dim = 8 + 2\n",
    "        self.device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.trade_env = build_env(args.env_class, args.env_args, gpu_id=args.gpu_id)\n",
    "\n",
    "        self.current_btc = 0\n",
    "        self.cash = [args.starting_cash]\n",
    "        self.btc_assets = [0]\n",
    "        # self.net_assets = [torch.tensor(args.starting_cash, device=self.device)]\n",
    "        self.net_assets = [args.starting_cash]\n",
    "        self.starting_cash = args.starting_cash\n",
    "        \n",
    "        self.random_seed = args.random_seed\n",
    "\n",
    "    def load_agents(self):\n",
    "        args = self.args\n",
    "        for agent_class in self.agent_classes:\n",
    "            agent = agent_class(\n",
    "                args.net_dims,\n",
    "                args.state_dim,\n",
    "                args.action_dim,\n",
    "                gpu_id=args.gpu_id,\n",
    "                args=args,\n",
    "            )\n",
    "            agent_name = agent_class.__name__\n",
    "            cwd = os.path.join(self.save_path, agent_name)\n",
    "            agent.save_or_load_agent(cwd, if_save=False)  # Load agent\n",
    "            self.agents.append(agent)\n",
    "\n",
    "    def multi_trade(self, strategy = \"majority_vote\"):\n",
    "        \"\"\"Evaluation loop using ensemble of agents\"\"\"\n",
    "        \n",
    "        torch.manual_seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        agents = self.agents\n",
    "        trade_env = self.trade_env\n",
    "        \n",
    "        state = trade_env.reset()\n",
    "\n",
    "        last_state = state\n",
    "        last_price = 0\n",
    "\n",
    "        positions = []\n",
    "        action_ints = []\n",
    "        correct_pred = []\n",
    "        current_btcs = [self.current_btc]\n",
    "\n",
    "        for _ in range(trade_env.max_step):\n",
    "            \n",
    "            actions = []\n",
    "            q_values_list = []\n",
    "            intermediate_state = last_state\n",
    "            \n",
    "\n",
    "            # Collect actions from each agent\n",
    "            for agent in agents:\n",
    "                with torch.no_grad():\n",
    "                    actor = agent.act\n",
    "\n",
    "                tensor_state = torch.as_tensor(intermediate_state, dtype=torch.float32, device=agent.device)\n",
    "                tensor_q_values = actor(tensor_state)\n",
    "                tensor_action = tensor_q_values.argmax(dim=1)\n",
    "                action = tensor_action.detach().cpu().unsqueeze(1)\n",
    "                actions.append(action)\n",
    "                q_values = tensor_q_values.cpu().detach()\n",
    "                q_values_list.append(q_values)\n",
    "\n",
    "            if strategy == \"Majority_Voting\":\n",
    "                action = self._ensemble_action_majority_voting(actions=actions)   \n",
    "            elif strategy == \"Confidence_Based\": # use Q value as confidence score\n",
    "                action = self._ensemble_action_confidence_based(q_values_list=q_values_list) \n",
    "            elif strategy == \"Boltzmann_Addition\":\n",
    "                action = self._ensemble_action_boltzmann_addition(q_values_list=q_values_list)\n",
    "            elif strategy == \"Boltzmann_Multiplication\":\n",
    "                action = self._ensemble_action_boltzmann_multiplication(q_values_list=q_values_list)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            \n",
    "            action_int = action.item() - 1\n",
    "\n",
    "            state, reward, done, _ = trade_env.step(action=action)\n",
    "            \n",
    "            # Transform to the actual action used in stepping\n",
    "            cur_pos = state[0][0].cpu().detach().numpy()\n",
    "            pre_pos = last_state[0][0].cpu().detach().numpy()\n",
    "            action_int = cur_pos - pre_pos            \n",
    "\n",
    "            action_ints.append(action_int)\n",
    "    \n",
    "            # The positions below are from trade_env, which is a result of post-processed action after \"stop loss\"\n",
    "            positions.append(trade_env.position)\n",
    "\n",
    "            # Manually compute cumulative returns\n",
    "            \n",
    "            # Adjust index to be consistent with trading env\n",
    "            # mid_price = trade_env.price_ary[trade_env.step_i, 2].to(self.device)\n",
    "            mid_price = trade_env.price_ary[trade_env.step_i + trade_env.step_is, 2].to(self.device)\n",
    "            new_cash = self.cash[-1]\n",
    "\n",
    "            if action_int > 0 and self.cash[-1] > mid_price:  # Buy\n",
    "                last_cash = self.cash[-1]\n",
    "                new_cash = last_cash - mid_price\n",
    "                self.current_btc += 1\n",
    "            elif action_int < 0 and self.current_btc > 0:  # Sell\n",
    "                last_cash = self.cash[-1]\n",
    "                new_cash = last_cash + mid_price\n",
    "                self.current_btc -= 1\n",
    "\n",
    "            self.cash.append(new_cash)\n",
    "            self.btc_assets.append((self.current_btc * mid_price).item())\n",
    "            self.net_assets.append((to_python_number(self.btc_assets[-1]) + to_python_number(new_cash)))\n",
    "\n",
    "            last_state = state\n",
    "\n",
    "            # Log win rate\n",
    "            if action_int == 1:\n",
    "                correct_pred.append(1 if last_price < mid_price else -1 if last_price > mid_price else 0)\n",
    "            elif action_int == -1:\n",
    "                correct_pred.append(-1 if last_price < mid_price else 1 if last_price > mid_price else 0)\n",
    "            else:\n",
    "                correct_pred.append(0)\n",
    "                \n",
    "#             print(\"last price\", last_price, \"mid price\", mid_price)\n",
    "#             print(\"action\", action_int)\n",
    "#             print(\"correct_pred\", correct_pred)\n",
    "\n",
    "            last_price = mid_price\n",
    "            current_btcs.append(self.current_btc)\n",
    "\n",
    "        num_trades = correct_pred.count(1) + correct_pred.count(-1)\n",
    "        num_wins = correct_pred.count(1)\n",
    "        \n",
    "        if num_trades > 0:\n",
    "            win_rate = num_wins/num_trades\n",
    "        else:\n",
    "            win_rate = 0\n",
    "\n",
    "        # Save results\n",
    "        if len(agents)>1:\n",
    "            positions = np.array([t.numpy() for t in positions]).flatten()\n",
    "            np.save(f\"{self.save_path}{strategy}_positions.npy\", np.array(positions))\n",
    "            np.save(f\"{self.save_path}{strategy}_net_assets.npy\", np.array(self.net_assets))\n",
    "            np.save(f\"{self.save_path}{strategy}_btc_positions.npy\", np.array(self.btc_assets))\n",
    "            np.save(f\"{self.save_path}{strategy}_correct_predictions.npy\", np.array(correct_pred))\n",
    "        \n",
    "        # Compute metrics\n",
    "        pnl = sum(np.diff(self.net_assets))\n",
    "        returns = np.diff(self.net_assets) / self.net_assets[:-1]\n",
    "        final_sharpe_ratio = sharpe_ratio(returns)\n",
    "        final_max_drawdown = max_drawdown(returns)\n",
    "        final_roma = return_over_max_drawdown(returns)\n",
    "        \n",
    "        print(f\"Initial Asset: {self.net_assets[0]}\")\n",
    "        print(f\"Final Asset: {self.net_assets[-1]}\")\n",
    "        print(f\"PnL: {pnl} \\n\")\n",
    "           \n",
    "        print(f\"Mean Return {returns.mean()}\")\n",
    "        print(f\"Volatility {returns.std()} \\n\")        \n",
    "        \n",
    "        print(f\"Sharpe Ratio: {final_sharpe_ratio}\")\n",
    "        print(f\"Max Drawdown: {final_max_drawdown}\")\n",
    "        print(f\"Return over Max Drawdown: {final_roma}\")\n",
    "        print(f\"Win Rate {win_rate}\")\n",
    "\n",
    "        \n",
    "        res = {\"Initial Asset\": self.net_assets[0],\n",
    "               \"Final Asset\": self.net_assets[-1],\n",
    "               \"PnL\": pnl,\n",
    "               \"Mean Return\": returns.mean(),\n",
    "               \"Volatility\": returns.std(),\n",
    "               \"Sharpe Ratio\": final_sharpe_ratio,\n",
    "               \"Max Drawdown\": final_max_drawdown,\n",
    "               \"Return over Max Drawdown\": final_roma,\n",
    "               \"Win Rate\": win_rate,\n",
    "              }\n",
    "               \n",
    "        return res\n",
    "\n",
    "    def _ensemble_action_majority_voting(self, actions):\n",
    "        \"\"\"Returns the majority action among agents. Our code uses majority voting, you may change this to increase performance.\"\"\"\n",
    "        count = Counter([a.item() for a in actions])\n",
    "        majority_action, _ = count.most_common(1)[0]\n",
    "        return torch.tensor([[majority_action]], dtype=torch.int32)\n",
    "\n",
    "    def _ensemble_action_confidence_based(self, q_values_list):\n",
    "        \"\"\"Returns the optimal action based on aggregated q values for all agents.\"\"\"\n",
    "        q_values_sum = sum(q_values_list)\n",
    "        action = q_values_sum.argmax(dim=1).unsqueeze(1)\n",
    "#         print(\"q values list\", q_values_list) \n",
    "#         print(\"q values values sum\",q_values_sum)\n",
    "#         print(\"action\", action)\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def _ensemble_action_boltzmann_addition(self, q_values_list):\n",
    "        \"\"\"Returns the optimal action based on the sum of boltzmann probabilities for all agents.\"\"\"\n",
    "        boltzmann_probabilities = [torch.softmax(q_values, dim=1) for q_values in q_values_list]\n",
    "        boltzmann_addition = torch.stack(boltzmann_probabilities).sum(dim=0)\n",
    "        action = boltzmann_addition.argmax(dim=1).unsqueeze(1)\n",
    "#         print(\"q values list\", q_values_list) \n",
    "#         print(\"boltzmann_probabilities\", boltzmann_probabilities)\n",
    "#         print(\"boltzmann_addition\",boltzmann_addition)\n",
    "#         print(\"action\", action)\n",
    "        return action\n",
    "\n",
    "    def _ensemble_action_boltzmann_multiplication(self, q_values_list):\n",
    "        \"\"\"Returns the optimal action based on the product of boltzmann probabilities for all agents.\"\"\"\n",
    "        q_values_sum = torch.zeros((1, 3), dtype=torch.float32)\n",
    "        boltzmann_probabilities = [torch.softmax(q_values, dim=1) for q_values in q_values_list]        \n",
    "        boltzmann_multiplication = torch.stack(boltzmann_probabilities).prod(dim=0)  \n",
    "        action = boltzmann_multiplication.argmax(dim=1).unsqueeze(1)\n",
    "#         print(\"q values list\", q_values_list) \n",
    "#         print(\"boltzmann_probabilities\", boltzmann_probabilities)\n",
    "#         print(\"boltzmann_multiplication\",boltzmann_multiplication)\n",
    "#         print(\"action\", action)\n",
    "        return action\n",
    "\n",
    "def run_evaluation(save_path, agent_list, strategy):\n",
    "    import sys\n",
    "\n",
    "    #gpu_id = int(sys.argv[1]) if len(sys.argv) > 1 else -1  # Get GPU_ID from command line arguments\n",
    "    gpu_id = -1\n",
    "    \n",
    "    num_sims = 1\n",
    "    num_ignore_step = 60\n",
    "    max_position = 1\n",
    "    step_gap = 2\n",
    "    slippage = 7e-7\n",
    "\n",
    "    max_step = (4800 - num_ignore_step) // step_gap\n",
    "\n",
    "    env_args = {\n",
    "        \"env_name\": \"TradeSimulator-v0\",\n",
    "        \"num_envs\": num_sims,\n",
    "        \"max_step\": max_step,\n",
    "        \"state_dim\": 8 + 2,\n",
    "        \"action_dim\": 3,\n",
    "        \"if_discrete\": True,\n",
    "        \"max_position\": max_position,\n",
    "        \"slippage\": slippage,\n",
    "        \"num_sims\": num_sims,\n",
    "        \"step_gap\": step_gap,\n",
    "        \n",
    "#         # use default dataset\n",
    "#         \"dataset_path\": \"path_to_evaluation_dataset\",  # Replace with your evaluation dataset path\n",
    "    }\n",
    "    args = Config(agent_class=None, env_class=EvalTradeSimulator, env_args=env_args)\n",
    "    args.gpu_id = gpu_id\n",
    "    args.random_seed = np.abs(gpu_id) #random seed need to be non-negative\n",
    "    args.net_dims = (128, 128, 128)\n",
    "    args.starting_cash = 1e6\n",
    "\n",
    "    ensemble_evaluator = EnsembleEvaluator(\n",
    "        save_path,\n",
    "        agent_list,\n",
    "        args,\n",
    "    )\n",
    "    ensemble_evaluator.load_agents()\n",
    "    res = ensemble_evaluator.multi_trade(strategy = strategy)\n",
    "    return res\n",
    "\n",
    "save_path = \"trained_agents/\"\n",
    "\n",
    "agent_list = [AgentDoubleDQN, AgentD3QN, AgentDiscretePPO, AgentDiscreteA2C,AgentDiscreteSAC]\n",
    "#agent_list = [AgentDoubleDQN]\n",
    "\n",
    "metrics_data = []\n",
    "for agent in agent_list:\n",
    "    print(f\"\\n------Individual Agent Performance: {agent.__name__}------\\n\")\n",
    "    metrics = run_evaluation(f\"{save_path}\", [agent], \"Majority_Voting\") #single action\n",
    "\n",
    "    metrics[\"Agent\"] = agent.__name__\n",
    "    metrics_data.append(metrics)\n",
    "\n",
    "for strategy in [\"Majority_Voting\", \"Confidence_Based\", \"Boltzmann_Addition\", \"Boltzmann_Multiplication\"]:\n",
    "    print(f\"\\n------Ensemble RL with {strategy}------\\n\")\n",
    "    metrics = run_evaluation(f\"{save_path}\", agent_list, strategy)\n",
    "\n",
    "    metrics[\"Agent\"] = \"Ensemble: \" + strategy\n",
    "    metrics_data.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df.insert(0, 'Agent', metrics_df.pop('Agent'))\n",
    "metrics_df.to_excel(\"evaluation_results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e9ebf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e5ca8_row0_col0, #T_e5ca8_row1_col0, #T_e5ca8_row2_col0, #T_e5ca8_row3_col0, #T_e5ca8_row4_col0, #T_e5ca8_row5_col0, #T_e5ca8_row6_col0, #T_e5ca8_row7_col0, #T_e5ca8_row8_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e5ca8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e5ca8_level0_col0\" class=\"col_heading level0 col0\" >Agent</th>\n",
       "      <th id=\"T_e5ca8_level0_col1\" class=\"col_heading level0 col1\" >Initial Asset</th>\n",
       "      <th id=\"T_e5ca8_level0_col2\" class=\"col_heading level0 col2\" >Final Asset</th>\n",
       "      <th id=\"T_e5ca8_level0_col3\" class=\"col_heading level0 col3\" >PnL</th>\n",
       "      <th id=\"T_e5ca8_level0_col4\" class=\"col_heading level0 col4\" >Mean Return</th>\n",
       "      <th id=\"T_e5ca8_level0_col5\" class=\"col_heading level0 col5\" >Volatility</th>\n",
       "      <th id=\"T_e5ca8_level0_col6\" class=\"col_heading level0 col6\" >Sharpe Ratio</th>\n",
       "      <th id=\"T_e5ca8_level0_col7\" class=\"col_heading level0 col7\" >Max Drawdown</th>\n",
       "      <th id=\"T_e5ca8_level0_col8\" class=\"col_heading level0 col8\" >Return over Max Drawdown</th>\n",
       "      <th id=\"T_e5ca8_level0_col9\" class=\"col_heading level0 col9\" >Win Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e5ca8_row0_col0\" class=\"data row0 col0\" >AgentDoubleDQN</td>\n",
       "      <td id=\"T_e5ca8_row0_col1\" class=\"data row0 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row0_col2\" class=\"data row0 col2\" >1002668</td>\n",
       "      <td id=\"T_e5ca8_row0_col3\" class=\"data row0 col3\" >2668.4</td>\n",
       "      <td id=\"T_e5ca8_row0_col4\" class=\"data row0 col4\" >0.00011%</td>\n",
       "      <td id=\"T_e5ca8_row0_col5\" class=\"data row0 col5\" >0.00492%</td>\n",
       "      <td id=\"T_e5ca8_row0_col6\" class=\"data row0 col6\" >2.290%</td>\n",
       "      <td id=\"T_e5ca8_row0_col7\" class=\"data row0 col7\" >-0.013%</td>\n",
       "      <td id=\"T_e5ca8_row0_col8\" class=\"data row0 col8\" >21.13</td>\n",
       "      <td id=\"T_e5ca8_row0_col9\" class=\"data row0 col9\" >76.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e5ca8_row1_col0\" class=\"data row1 col0\" >AgentD3QN</td>\n",
       "      <td id=\"T_e5ca8_row1_col1\" class=\"data row1 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row1_col2\" class=\"data row1 col2\" >1000546</td>\n",
       "      <td id=\"T_e5ca8_row1_col3\" class=\"data row1 col3\" >546.2</td>\n",
       "      <td id=\"T_e5ca8_row1_col4\" class=\"data row1 col4\" >0.00002%</td>\n",
       "      <td id=\"T_e5ca8_row1_col5\" class=\"data row1 col5\" >0.00028%</td>\n",
       "      <td id=\"T_e5ca8_row1_col6\" class=\"data row1 col6\" >8.283%</td>\n",
       "      <td id=\"T_e5ca8_row1_col7\" class=\"data row1 col7\" >-0.005%</td>\n",
       "      <td id=\"T_e5ca8_row1_col8\" class=\"data row1 col8\" >10.50</td>\n",
       "      <td id=\"T_e5ca8_row1_col9\" class=\"data row1 col9\" >75.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e5ca8_row2_col0\" class=\"data row2 col0\" >AgentDiscretePPO</td>\n",
       "      <td id=\"T_e5ca8_row2_col1\" class=\"data row2 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row2_col2\" class=\"data row2 col2\" >1005158</td>\n",
       "      <td id=\"T_e5ca8_row2_col3\" class=\"data row2 col3\" >5158.2</td>\n",
       "      <td id=\"T_e5ca8_row2_col4\" class=\"data row2 col4\" >0.00022%</td>\n",
       "      <td id=\"T_e5ca8_row2_col5\" class=\"data row2 col5\" >0.00983%</td>\n",
       "      <td id=\"T_e5ca8_row2_col6\" class=\"data row2 col6\" >2.214%</td>\n",
       "      <td id=\"T_e5ca8_row2_col7\" class=\"data row2 col7\" >-0.032%</td>\n",
       "      <td id=\"T_e5ca8_row2_col8\" class=\"data row2 col8\" >16.21</td>\n",
       "      <td id=\"T_e5ca8_row2_col9\" class=\"data row2 col9\" >77.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e5ca8_row3_col0\" class=\"data row3 col0\" >AgentDiscreteA2C</td>\n",
       "      <td id=\"T_e5ca8_row3_col1\" class=\"data row3 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row3_col2\" class=\"data row3 col2\" >1005193</td>\n",
       "      <td id=\"T_e5ca8_row3_col3\" class=\"data row3 col3\" >5193.0</td>\n",
       "      <td id=\"T_e5ca8_row3_col4\" class=\"data row3 col4\" >0.00022%</td>\n",
       "      <td id=\"T_e5ca8_row3_col5\" class=\"data row3 col5\" >0.00983%</td>\n",
       "      <td id=\"T_e5ca8_row3_col6\" class=\"data row3 col6\" >2.229%</td>\n",
       "      <td id=\"T_e5ca8_row3_col7\" class=\"data row3 col7\" >-0.037%</td>\n",
       "      <td id=\"T_e5ca8_row3_col8\" class=\"data row3 col8\" >14.06</td>\n",
       "      <td id=\"T_e5ca8_row3_col9\" class=\"data row3 col9\" >76.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e5ca8_row4_col0\" class=\"data row4 col0\" >AgentDiscreteSAC</td>\n",
       "      <td id=\"T_e5ca8_row4_col1\" class=\"data row4 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row4_col2\" class=\"data row4 col2\" >1000290</td>\n",
       "      <td id=\"T_e5ca8_row4_col3\" class=\"data row4 col3\" >289.6</td>\n",
       "      <td id=\"T_e5ca8_row4_col4\" class=\"data row4 col4\" >0.00001%</td>\n",
       "      <td id=\"T_e5ca8_row4_col5\" class=\"data row4 col5\" >0.00035%</td>\n",
       "      <td id=\"T_e5ca8_row4_col6\" class=\"data row4 col6\" >3.476%</td>\n",
       "      <td id=\"T_e5ca8_row4_col7\" class=\"data row4 col7\" >-0.012%</td>\n",
       "      <td id=\"T_e5ca8_row4_col8\" class=\"data row4 col8\" >2.38</td>\n",
       "      <td id=\"T_e5ca8_row4_col9\" class=\"data row4 col9\" >77.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e5ca8_row5_col0\" class=\"data row5 col0\" >Ensemble: Majority_Voting</td>\n",
       "      <td id=\"T_e5ca8_row5_col1\" class=\"data row5 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row5_col2\" class=\"data row5 col2\" >1005015</td>\n",
       "      <td id=\"T_e5ca8_row5_col3\" class=\"data row5 col3\" >5015.3</td>\n",
       "      <td id=\"T_e5ca8_row5_col4\" class=\"data row5 col4\" >0.00021%</td>\n",
       "      <td id=\"T_e5ca8_row5_col5\" class=\"data row5 col5\" >0.00983%</td>\n",
       "      <td id=\"T_e5ca8_row5_col6\" class=\"data row5 col6\" >2.152%</td>\n",
       "      <td id=\"T_e5ca8_row5_col7\" class=\"data row5 col7\" >-0.043%</td>\n",
       "      <td id=\"T_e5ca8_row5_col8\" class=\"data row5 col8\" >11.59</td>\n",
       "      <td id=\"T_e5ca8_row5_col9\" class=\"data row5 col9\" >75.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e5ca8_row6_col0\" class=\"data row6 col0\" >Ensemble: Confidence_Based</td>\n",
       "      <td id=\"T_e5ca8_row6_col1\" class=\"data row6 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row6_col2\" class=\"data row6 col2\" >1000556</td>\n",
       "      <td id=\"T_e5ca8_row6_col3\" class=\"data row6 col3\" >555.7</td>\n",
       "      <td id=\"T_e5ca8_row6_col4\" class=\"data row6 col4\" >0.00002%</td>\n",
       "      <td id=\"T_e5ca8_row6_col5\" class=\"data row6 col5\" >0.00028%</td>\n",
       "      <td id=\"T_e5ca8_row6_col6\" class=\"data row6 col6\" >8.429%</td>\n",
       "      <td id=\"T_e5ca8_row6_col7\" class=\"data row6 col7\" >-0.005%</td>\n",
       "      <td id=\"T_e5ca8_row6_col8\" class=\"data row6 col8\" >11.84</td>\n",
       "      <td id=\"T_e5ca8_row6_col9\" class=\"data row6 col9\" >75.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e5ca8_row7_col0\" class=\"data row7 col0\" >Ensemble: Boltzmann_Addition</td>\n",
       "      <td id=\"T_e5ca8_row7_col1\" class=\"data row7 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row7_col2\" class=\"data row7 col2\" >1000554</td>\n",
       "      <td id=\"T_e5ca8_row7_col3\" class=\"data row7 col3\" >554.2</td>\n",
       "      <td id=\"T_e5ca8_row7_col4\" class=\"data row7 col4\" >0.00002%</td>\n",
       "      <td id=\"T_e5ca8_row7_col5\" class=\"data row7 col5\" >0.00028%</td>\n",
       "      <td id=\"T_e5ca8_row7_col6\" class=\"data row7 col6\" >8.406%</td>\n",
       "      <td id=\"T_e5ca8_row7_col7\" class=\"data row7 col7\" >-0.005%</td>\n",
       "      <td id=\"T_e5ca8_row7_col8\" class=\"data row7 col8\" >11.81</td>\n",
       "      <td id=\"T_e5ca8_row7_col9\" class=\"data row7 col9\" >75.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5ca8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e5ca8_row8_col0\" class=\"data row8 col0\" >Ensemble: Boltzmann_Multiplication</td>\n",
       "      <td id=\"T_e5ca8_row8_col1\" class=\"data row8 col1\" >1000000</td>\n",
       "      <td id=\"T_e5ca8_row8_col2\" class=\"data row8 col2\" >1000556</td>\n",
       "      <td id=\"T_e5ca8_row8_col3\" class=\"data row8 col3\" >555.7</td>\n",
       "      <td id=\"T_e5ca8_row8_col4\" class=\"data row8 col4\" >0.00002%</td>\n",
       "      <td id=\"T_e5ca8_row8_col5\" class=\"data row8 col5\" >0.00028%</td>\n",
       "      <td id=\"T_e5ca8_row8_col6\" class=\"data row8 col6\" >8.429%</td>\n",
       "      <td id=\"T_e5ca8_row8_col7\" class=\"data row8 col7\" >-0.005%</td>\n",
       "      <td id=\"T_e5ca8_row8_col8\" class=\"data row8 col8\" >11.84</td>\n",
       "      <td id=\"T_e5ca8_row8_col9\" class=\"data row8 col9\" >75.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe9fe761630>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = metrics_df.copy()\n",
    "df['Initial Asset'] = df['Initial Asset'].apply(lambda x: f\"{x:.0f}\")\n",
    "df['Final Asset'] = df['Final Asset'].apply(lambda x: f\"{x:.0f}\")\n",
    "df['PnL'] = df['PnL'].apply(lambda x: f\"{x:.1f}\")\n",
    "df['Mean Return'] = df['Mean Return'].apply(lambda x: f\"{x * 100:.5f}%\")\n",
    "df['Volatility'] = df['Volatility'].apply(lambda x: f\"{x * 100:.5f}%\")\n",
    "#df['Sharpe Ratio'] = df['Sharpe Ratio'].apply(lambda x: f\"{x * 100:.3f}%\")\n",
    "df['Max Drawdown'] = df['Max Drawdown'].apply(lambda x: f\"{x * 100:.3f}%\")\n",
    "df['Return over Max Drawdown'] = df['Return over Max Drawdown'].apply(lambda x: f\"{x:.2f}\")\n",
    "df['Win Rate'] = df['Win Rate'].apply(lambda x: f\"{x * 100:.1f}%\")\n",
    "df = df.style.set_properties(subset=['Agent'], **{'text-align': 'left'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700dd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
